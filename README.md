# ðŸ¤– AI Conversational Chatbot with LangGraph, Mistral & LangSmith

An AI-powered conversational chatbot built using **LangGraph**, **LangChain**, and **Mistral LLM**, featuring **multi-threaded conversation memory**, **persistent SQLite checkpointing**, **LangSmith observability**, and an interactive **Streamlit UI**.

This project demonstrates **state-based LLM orchestration**, **conversation-level memory management**, and **production-grade AI application practices**.

---

## âœ¨ Key Features

* ðŸ§  **State-based conversation flow** using LangGraph
* ðŸ’¬ **Multi-threaded conversations** (each chat has its own memory)
* ðŸ’¾ **Persistent memory** using SQLite checkpointer
* ðŸ”„ **Conversation switching** via sidebar
* ðŸ·ï¸ **Automatic conversation title generation**
* âš¡ **Real-time streaming AI responses**
* ðŸŒ **Interactive web UI** with Streamlit
* ðŸ” **LangSmith tracing & observability**
* ðŸ” **Secure API key management** using environment variables

---

## ðŸ—ï¸ Architecture Overview

```
User (Browser)
    â”‚
    â–¼
Streamlit Frontend
    â”‚
    â–¼
LangGraph State Machine
    â”‚
    â–¼
Mistral LLM (ChatMistralAI)
    â”‚
    â–¼
SQLite Checkpointer (Persistent Memory)
    â”‚
    â–¼
LangSmith (Tracing & Monitoring)
```

---

## ðŸ“ Project Structure

```
AI-Conversational-Chatbot-with-LangGraph-Mistral/
â”‚
â”œâ”€â”€ Frontend.py        # Streamlit user interface
â”œâ”€â”€ Backend2.py        # LangGraph backend logic
â”œâ”€â”€ chatbot.db         # SQLite database (auto-generated)
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ .gitignore         # Ignored files
â”œâ”€â”€ .env               # API keys (NOT committed)
â””â”€â”€ README.md
```

---

## ðŸ§  How It Works

### ðŸ”¹ Backend (LangGraph)

* Uses a `StateGraph` to model the conversation as a state machine
* Each message updates the graph state
* Messages are stored using a **SQLite checkpointer**
* Conversations are isolated using a unique `thread_id`

### ðŸ”¹ Frontend (Streamlit)

* Sidebar lists all previous conversations
* Users can switch conversations instantly
* First few messages are summarized into a short conversation title
* Assistant responses are streamed token-by-token

---

## ðŸ” LangSmith Integration (Tracing & Observability)

This project integrates **LangSmith** to enable deep visibility into LLM execution.

LangSmith provides:

* Prompt â†’ response tracing
* LangGraph node execution inspection
* Latency and token usage tracking
* Debugging across conversation threads

---

### ðŸ”§ LangSmith Environment Configuration

Add the following to your `.env` file:

```env
# Enable LangSmith tracing
LANGCHAIN_TRACING_V2=true

# LangSmith endpoint
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# LangSmith API key
LANGCHAIN_API_KEY=your_langsmith_api_key_here

# Project name shown in LangSmith dashboard
LANGCHAIN_PROJECT=chat bot with langsmith
```

âš ï¸ **Never commit real API keys to GitHub**

---

### ðŸ› ï¸ How Tracing Works

Once enabled:

* All `llm.invoke()` calls are traced
* Each LangGraph node execution is recorded
* Conversation flows can be analyzed per thread

No additional code changes are required.

---

## ðŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/umerrafiq04/AI-Conversational-Chatbot-with-LangGraph-Mistral.git
cd AI-Conversational-Chatbot-with-LangGraph-Mistral
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Linux / macOS
venv\Scripts\activate      # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file:

```env
MISTRAL_API_KEY=your_mistral_api_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=chat bot with langsmith
```

---

### 5ï¸âƒ£ Run the Application

```bash
streamlit run Frontend.py
```

Open in browser:

```
http://localhost:8501
```

---

## ðŸ” Security Best Practices

* API keys are stored in `.env`
* `.env`, database files, and virtual environments are excluded via `.gitignore`
* No secrets are committed to version control

Example `.gitignore`:

```gitignore
.env
*.db
venv/
__pycache__/
```

---

## ðŸ“¦ Tech Stack

| Layer         | Technology  |
| ------------- | ----------- |
| UI            | Streamlit   |
| LLM           | Mistral     |
| Orchestration | LangGraph   |
| Framework     | LangChain   |
| Memory        | SQLite      |
| Observability | LangSmith   |
| Language      | Python 3.12 |

---

## ðŸ§ª Example Use Cases

* Persistent AI chat assistant
* Multi-session conversational agents
* LangGraph learning & experimentation
* LLM observability demonstrations
* Portfolio-ready AI engineering project

---

## ðŸ“Œ Future Enhancements

* ðŸ—‘ï¸ Delete / rename conversations
* ðŸ“„ Export chats to PDF
* ðŸ³ Dockerized deployment
* â˜ï¸ Cloud hosting (Streamlit Cloud / Azure / AWS)
* ðŸ”„ Replace SQLite with Redis / PostgreSQL
* ðŸ§© Tool & agent integrations

---

## ðŸ‘¨â€ðŸ’» Author

**Umer Rafiq**
BTech Computer Science & Engineering
AI & Web Development Enthusiast
ðŸ“ Kashmir, India

---

## â­ Support

If you found this project useful:

* Give it a â­ on GitHub
* Fork and extend it
* Share feedback or improvements

---

## ðŸ“£ Recruiter Note

> This project demonstrates hands-on experience with **LLM orchestration**, **state machines**, **persistent memory**, **streaming responses**, and **observability using LangSmith**, reflecting real-world AI system design practices.

---


